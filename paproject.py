# -*- coding: utf-8 -*-
"""PAproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yYxxW-6xOlllP3b1cEQtOIFWe-elTMOE
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Suppress warnings
warnings.filterwarnings("ignore")

# a) Import data & info()
nycgreen = pd.read_parquet("/content/green_tripdata_2023-02.parquet")
print("Dataset Information:")
nycgreen.info()

# b) Drop ehail_fee column
nycgreen = nycgreen.drop("ehail_fee", axis=1)

# c) Calculate trip_duration based on pickup & dropoff date
nycgreen["trip_duration"] = nycgreen.lpep_dropoff_datetime - nycgreen.lpep_pickup_datetime
# Convert to minutes
nycgreen["trip_duration"] = nycgreen["trip_duration"].dt.total_seconds() / 60
print("\nTrip Duration (first 5 records):")
print(nycgreen["trip_duration"].head(5))

# d) Extract weekday
nycgreen["weekday"] = nycgreen["lpep_dropoff_datetime"].dt.day_name()
print("\nWeekday Distribution:")
print(nycgreen["weekday"].value_counts(dropna=False))

# e) Extract hour
nycgreen["hour"] = nycgreen["lpep_dropoff_datetime"].dt.hour
print("\nHour Distribution:")
print(nycgreen["hour"].value_counts(dropna=False).sort_index())

# f) Missing Values Imputation
# Split Data into obj & num cols
objcols = nycgreen[['VendorID', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID',
                  'DOLocationID', 'payment_type', 'trip_type', 'weekday', 'hour']]
numcols = nycgreen.drop(columns=objcols.columns)
# Drop Datetime variables
numcols = numcols.drop(['lpep_pickup_datetime', 'lpep_dropoff_datetime'], axis=1)

# Check for missing values in objcols
print("\nMissing Values in Object Columns:")
for col in objcols.columns:
    missing = objcols[col].isna().sum()
    print(f"{col}: {missing} ({missing/len(objcols)*100:.2f}%)")

# Check for missing values in numcols
print("\nMissing Values in Numeric Columns:")
for col in numcols.columns:
    missing = numcols[col].isna().sum()
    print(f"{col}: {missing} ({missing/len(numcols)*100:.2f}%)")

# Impute missing values in objcols with most frequent class/level
for col in objcols.columns:
    objcols[col] = objcols[col].fillna(objcols[col].value_counts().idxmax())

# Median Imputation for numeric columns
for col in numcols.columns:
    numcols[col] = numcols[col].fillna(numcols[col].median())

# Load location lookup data
#location_id = pd.read_csv(r"C:\Users\kaila\Downloads\taxi_zone_lookup (1).csv")
# rename columns in location_id
#location_id = location_id.rename(columns={'LocationID': 'PULocationID',
#                                        'Zone': 'PUZone'})

# Left Join of nycgreen and location_id dataframes
#objcols = objcols.merge(location_id, on="PULocationID", how="left")
#location_id = location_id.rename(columns={"PULocationID": "DOLocationID",
#                                        "PUZone": "DOZone"})
#objcols = objcols.merge(location_id, on="DOLocationID", how="left")

# Check if loading lookup data was successful
#print("\nSample merged data (first 5 rows):")
#print(objcols[['PULocationID', 'PUZone', 'DOLocationID', 'DOZone']].head(5))

# g) Pie diagram of payment_type, trip_type
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
payment_counts = nycgreen['payment_type'].value_counts()
payment_labels = [f'Type {k} ({v})' for k, v in payment_counts.items()]
plt.pie(payment_counts, autopct='%1.1f%%', startangle=90, labels=payment_labels)
plt.title('Distribution of Payment Types')
plt.axis('equal')

plt.subplot(1, 2, 2)
trip_counts = nycgreen['trip_type'].value_counts()
trip_labels = [f'Type {k} ({v})' for k, v in trip_counts.items()]
plt.pie(trip_counts, autopct='%1.1f%%', startangle=90, labels=trip_labels)
plt.title('Distribution of Trip Types')
plt.axis('equal')

plt.tight_layout()
plt.savefig('payment_trip_type_pie.png')
plt.close()

# h) Groupby() of average total_amount & weekday
weekday_amount = nycgreen.groupby('weekday')['total_amount'].mean().reset_index()
weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
weekday_amount['weekday'] = pd.Categorical(weekday_amount['weekday'], categories=weekday_order, ordered=True)
weekday_amount = weekday_amount.sort_values('weekday')

plt.figure(figsize=(10, 6))
sns.barplot(x='weekday', y='total_amount', data=weekday_amount)
plt.title('Average Total Amount by Weekday')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('avg_amount_by_weekday.png')
plt.close()

print("\nAverage Total Amount by Weekday:")
print(weekday_amount)

# i) Groupby() of average total_amount & payment_type
payment_amount = nycgreen.groupby('payment_type')['total_amount'].mean().reset_index()
plt.figure(figsize=(8, 5))
sns.barplot(x='payment_type', y='total_amount', data=payment_amount)
plt.title('Average Total Amount by Payment Type')
plt.tight_layout()
plt.savefig('avg_amount_by_payment.png')
plt.close()

print("\nAverage Total Amount by Payment Type:")
print(payment_amount)

# j) Groupby() of average tip_amount & weekday
weekday_tip = nycgreen.groupby('weekday')['tip_amount'].mean().reset_index()
weekday_tip['weekday'] = pd.Categorical(weekday_tip['weekday'], categories=weekday_order, ordered=True)
weekday_tip = weekday_tip.sort_values('weekday')

plt.figure(figsize=(10, 6))
sns.barplot(x='weekday', y='tip_amount', data=weekday_tip)
plt.title('Average Tip Amount by Weekday')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('avg_tip_by_weekday.png')
plt.close()

print("\nAverage Tip Amount by Weekday:")
print(weekday_tip)

# k) Groupby() of average tip_amount & payment_type
payment_tip = nycgreen.groupby('payment_type')['tip_amount'].mean().reset_index()
plt.figure(figsize=(8, 5))
sns.barplot(x='payment_type', y='tip_amount', data=payment_tip)
plt.title('Average Tip Amount by Payment Type')
plt.tight_layout()
plt.savefig('avg_tip_by_payment.png')
plt.close()

print("\nAverage Tip Amount by Payment Type:")
print(payment_tip)

# l) Test null average total_amount of different trip_type is identical
# ANOVA test for trip_type
trip_types = nycgreen['trip_type'].dropna().unique()
trip_type_groups = [nycgreen[nycgreen['trip_type'] == tt]['total_amount'].dropna() for tt in trip_types]
# Filter out empty groups
trip_type_groups = [group for group in trip_type_groups if len(group) > 0]

if len(trip_type_groups) >= 2:  # Need at least 2 groups for ANOVA
    f_stat, p_val = stats.f_oneway(*trip_type_groups)
    print("\nANOVA test for average total_amount across trip types:")
    print(f"F-statistic: {f_stat:.4f}, p-value: {p_val:.4f}")
    conclusion = "is not" if p_val < 0.05 else "is"
    print(f"Conclusion: The average total_amount {conclusion} identical across different trip types.")
else:
    print("\nCannot perform ANOVA test for trip types: insufficient groups with data.")

# m) Test null average total_amount of different weekday is identical
weekdays = nycgreen['weekday'].dropna().unique()
weekday_groups = [nycgreen[nycgreen['weekday'] == wd]['total_amount'].dropna() for wd in weekdays]
# Filter out empty groups
weekday_groups = [group for group in weekday_groups if len(group) > 0]

if len(weekday_groups) >= 2:  # Need at least 2 groups for ANOVA
    f_stat, p_val = stats.f_oneway(*weekday_groups)
    print("\nANOVA test for average total_amount across weekdays:")
    print(f"F-statistic: {f_stat:.4f}, p-value: {p_val:.4f}")
    conclusion = "is not" if p_val < 0.05 else "is"
    print(f"Conclusion: The average total_amount {conclusion} identical across different weekdays.")
else:
    print("\nCannot perform ANOVA test for weekdays: insufficient groups with data.")

# n) Test null no association between trip_type and payment_type
# Creating a contingency table
cont_table = pd.crosstab(nycgreen['trip_type'], nycgreen['payment_type'])
chi2, p, dof, expected = stats.chi2_contingency(cont_table)
print("\nChi-square test for association between trip_type and payment_type:")
print(f"Chi2 value: {chi2:.4f}, p-value: {p:.4f}")
conclusion = "is" if p < 0.05 else "is no"
print(f"Conclusion: There {conclusion} significant association between trip_type and payment_type.")

# o) and p) Define numeric and object variables
# Numeric variables
numeric_cols = ['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount',
                'tolls_amount', 'improvement_surcharge', 'congestion_surcharge',
                'trip_duration', 'passenger_count', 'total_amount']
numeric_data = nycgreen[numeric_cols]

# Object variables (categorical)
cat_cols = ['store_and_fwd_flag', 'RatecodeID', 'payment_type', 'trip_type', 'weekday', 'hour']
cat_data = nycgreen[cat_cols]

# q) Correlation analysis of numeric cols
plt.figure(figsize=(12, 10))
corr = numeric_data.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt='.2f')
plt.title('Correlation Matrix of Numeric Variables')
plt.tight_layout()
plt.savefig('correlation_matrix.png')
plt.close()

print("\nCorrelation Matrix:")
print(corr)

# r) Dummy encode object cols
cat_data_encoded = pd.get_dummies(cat_data, drop_first=True)
print("\nEncoded categorical variables shape:", cat_data_encoded.shape)

# s) Dependent Variable is total_amount - Histogram, Boxplot and Density Curve
plt.figure(figsize=(18, 6))

# Histogram
plt.subplot(1, 3, 1)
sns.histplot(nycgreen['total_amount'], kde=True, bins=50)
plt.title('Histogram of Total Amount')
plt.xlabel('Total Amount')

# Boxplot
plt.subplot(1, 3, 2)
sns.boxplot(y=nycgreen['total_amount'])
plt.title('Boxplot of Total Amount')
plt.ylabel('Total Amount')

# Density Curve
plt.subplot(1, 3, 3)
sns.kdeplot(nycgreen['total_amount'], fill=True)
plt.title('Density Curve of Total Amount')
plt.xlabel('Total Amount')

plt.tight_layout()
plt.savefig('total_amount_distribution.png')
plt.close()

# Calculate and print summary statistics
total_amount_stats = nycgreen['total_amount'].describe()
print("\nTotal Amount Summary Statistics:")
print(total_amount_stats)

# t) Building Regression Models
# Prepare the data
# Remove extreme outliers for better model performance
q1 = nycgreen['total_amount'].quantile(0.01)
q3 = nycgreen['total_amount'].quantile(0.99)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

# Filter data
filtered_data = nycgreen[(nycgreen['total_amount'] >= lower_bound) &
                        (nycgreen['total_amount'] <= upper_bound)]

print(f"\nData shape before outlier removal: {nycgreen.shape}")
print(f"Data shape after outlier removal: {filtered_data.shape}")

# Extract features from filtered data
X_numeric = filtered_data[['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount',
                          'tolls_amount', 'improvement_surcharge', 'congestion_surcharge',
                          'trip_duration', 'passenger_count']]

# Create dummy variables for categorical features
X_cat = pd.get_dummies(filtered_data[['store_and_fwd_flag', 'RatecodeID', 'payment_type',
                                     'trip_type', 'weekday', 'hour']], drop_first=True)

# Combine features
X = pd.concat([X_numeric, X_cat], axis=1)
y = filtered_data['total_amount']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nTraining set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

# Handle missing values
from sklearn.impute import SimpleImputer
import pickle

imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)

# Function to evaluate and print model results
def evaluate_model(model, model_name, X_train, X_test, y_train, y_test, X_full):
    # Train the model
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Cross-validation score
    cv_scores = cross_val_score(model, X_full, y, cv=5, scoring='r2')
    avg_cv_score = np.mean(cv_scores)

    # Print results
    print(f"\n{model_name} Results:")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R² Score: {r2:.4f}")
    print(f"5-Fold CV Average R² Score: {avg_cv_score:.4f}")

    return model, mse, rmse, r2, avg_cv_score

# 1. Multiple Linear Regression
print("\nTraining Multiple Linear Regression model...")
linear_model = LinearRegression()
linear_results = evaluate_model(linear_model, "Multiple Linear Regression", X_train, X_test, y_train, y_test, X_imputed)

# 2. Decision Tree
print("\nTraining Decision Tree model...")
dt_model = DecisionTreeRegressor(random_state=42)
dt_results = evaluate_model(dt_model, "Decision Tree", X_train, X_test, y_train, y_test, X_imputed)

# 3. Random Forest with 100 trees
print("\nTraining Random Forest model (100 trees)...")
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_results = evaluate_model(rf_model, "Random Forest (100 trees)", X_train, X_test, y_train, y_test, X_imputed)

# 4. Gradient Boosting with 100 trees
print("\nTraining Gradient Boosting model (100 trees)...")
gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
gb_results = evaluate_model(gb_model, "Gradient Boosting (100 trees)", X_train, X_test, y_train, y_test, X_imputed)

# Compare all models
models = ["Linear Regression", "Decision Tree", "Random Forest", "Gradient Boosting"]
r2_scores = [linear_results[3], dt_results[3], rf_results[3], gb_results[3]]
cv_scores = [linear_results[4], dt_results[4], rf_results[4], gb_results[4]]

# Plot comparison
plt.figure(figsize=(12, 6))

# R² scores comparison
plt.subplot(1, 2, 1)
bars = plt.bar(models, r2_scores, color=['blue', 'green', 'orange', 'red'])
plt.ylim(0, 1)
plt.title('R² Score Comparison')
plt.ylabel('R² Score')
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.4f}',
             ha='center', va='bottom', rotation=0)

# CV scores comparison
plt.subplot(1, 2, 2)
bars = plt.bar(models, cv_scores, color=['blue', 'green', 'orange', 'red'])
plt.ylim(0, 1)
plt.title('Cross-Validation R² Score Comparison')
plt.ylabel('CV R² Score')
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.4f}',
             ha='center', va='bottom', rotation=0)

plt.tight_layout()
plt.savefig('model_comparison.png')
plt.close()

# Feature importance for Random Forest (best model)
if hasattr(rf_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'Feature': X.columns,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)

    # Plot top 15 important features
    plt.figure(figsize=(12, 8))
    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))
    plt.title('Top 15 Feature Importance (Random Forest)')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    plt.close()

    print("\nTop 10 Most Important Features (Random Forest):")
    print(feature_importance.head(10))

# Save the best model (Random Forest)
with open('nyc_taxi_fare_rf_model.pkl', 'wb') as f:
    pickle.dump(rf_model, f)

print("\nRandom Forest model saved as 'nyc_taxi_fare_rf_model.pkl'")
print("\nAnalysis complete!")

!pip install streamlit

# Streamlit app for the NYC Taxi Fare Prediction
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

def main():
    # App title and description
    st.title("NYC Green Taxi Fare Predictor")
    st.write("This app predicts the total fare amount for NYC green taxi rides based on a Multiple Linear Regression model")

    # Try to load the model
    try:
        with open('nyc_taxi_fare_rf_model.pkl', 'rb') as f:
            model = pickle.load(f)
        model_loaded = True
        st.success("Model loaded successfully!")
    except:
        st.warning("Model file not found. Using simplified calculation instead.")
        model_loaded = False

    # Sidebar for inputs
    st.sidebar.header("Ride Information")

    # Collecting user inputs
    trip_distance = st.sidebar.slider("Trip Distance (miles)", 0.1, 30.0, 2.5)
    passenger_count = st.sidebar.slider("Number of Passengers", 1, 6, 1)
    trip_duration = st.sidebar.slider("Trip Duration (minutes)", 1, 120, 15)

    # Payment Type
    payment_options = {
        "Credit Card": 1,
        "Cash": 2,
        "No Charge": 3,
        "Dispute": 4,
        "Unknown": 5
    }
    payment_type = st.sidebar.selectbox("Payment Type", list(payment_options.keys()))
    payment_type_value = payment_options[payment_type]

    # Trip Type
    trip_type_options = ["Street-hail", "Dispatch"]
    trip_type = st.sidebar.selectbox("Trip Type", trip_type_options)
    trip_type_value = 1 if trip_type == "Street-hail" else 2

    # Day of the week
    weekday_options = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    weekday = st.sidebar.selectbox("Day of the Week", weekday_options)

    # Hour of the day
    hour = st.sidebar.slider("Hour of the Day (24h)", 0, 23, 12)

    # Additional charges
    st.sidebar.subheader("Additional Charges")
    fare_amount = st.sidebar.slider("Base Fare Amount ($)", 2.5, 20.0, 2.5)
    extra = st.sidebar.slider("Extra Charges ($)", 0.0, 5.0, 0.0)
    mta_tax = st.sidebar.slider("MTA Tax ($)", 0.0, 1.0, 0.5)
    tip_amount = st.sidebar.slider("Tip Amount ($)", 0.0, 20.0, 0.0)
    tolls_amount = st.sidebar.slider("Tolls Amount ($)", 0.0, 20.0, 0.0)
    improvement_surcharge = st.sidebar.slider("Improvement Surcharge ($)", 0.0, 1.0, 0.3)
    congestion_surcharge = st.sidebar.slider("Congestion Surcharge ($)", 0.0, 3.0, 2.5)

    # Main panel
    st.header("Prediction")

    # Prediction logic
    if model_loaded:
        input_data = {
            'trip_distance': trip_distance,
            'fare_amount': fare_amount,
            'extra': extra,
            'mta_tax': mta_tax,
            'tip_amount': tip_amount,
            'tolls_amount': tolls_amount,
            'improvement_surcharge': improvement_surcharge,
            'congestion_surcharge': congestion_surcharge,
            'trip_duration': trip_duration,
            'passenger_count': passenger_count,
            'payment_type_2': 1 if payment_type_value == 2 else 0,
            'payment_type_3': 1 if payment_type_value == 3 else 0,
            'payment_type_4': 1 if payment_type_value == 4 else 0,
            'payment_type_5': 1 if payment_type_value == 5 else 0,
            'trip_type_2': 1 if trip_type_value == 2 else 0,
            'weekday_Monday': 1 if weekday == 'Monday' else 0,
            'weekday_Saturday': 1 if weekday == 'Saturday' else 0,
            'weekday_Sunday': 1 if weekday == 'Sunday' else 0,
            'weekday_Thursday': 1 if weekday == 'Thursday' else 0,
            'weekday_Tuesday': 1 if weekday == 'Tuesday' else 0,
            'weekday_Wednesday': 1 if weekday == 'Wednesday' else 0,
            f'hour_{hour}': 1
        }

        input_df = pd.DataFrame([input_data])

        try:
            predicted_fare = model.predict(input_df)[0]
            st.subheader(f"Predicted Total Fare: ${predicted_fare:.2f}")
        except Exception as e:
            st.error(f"Error making prediction: {e}")
            model_loaded = False

    if not model_loaded:
        base_fare = fare_amount
        per_mile_rate = 2.50
        per_minute_rate = 0.35
        estimated_fare = base_fare + (trip_distance * per_mile_rate) + (trip_duration * per_minute_rate)
        estimated_fare += extra + mta_tax + tip_amount + tolls_amount + improvement_surcharge + congestion_surcharge
        st.subheader(f"Estimated Total Fare: ${estimated_fare:.2f}")

    # Explanation section
    st.header("Fare Breakdown")
    breakdown = {
        "Base Fare": f"${fare_amount:.2f}",
        "Distance Charge (estimated)": f"${trip_distance * 2.50:.2f}",
        "Time Charge (estimated)": f"${trip_duration * 0.35:.2f}",
        "Extra": f"${extra:.2f}",
        "MTA Tax": f"${mta_tax:.2f}",
        "Tip": f"${tip_amount:.2f}",
        "Tolls": f"${tolls_amount:.2f}",
        "Improvement Surcharge": f"${improvement_surcharge:.2f}",
        "Congestion Surcharge": f"${congestion_surcharge:.2f}"
    }
    for item, value in breakdown.items():
        st.write(f"{item}: {value}")

    # Data visualization section
    st.header("Data Visualization")
    tab1, tab2, tab3 = st.tabs(["Fare by Distance", "Fare by Time", "Payment Types"])

    with tab1:
        st.subheader("Relationship between Trip Distance and Fare")
        distances = np.linspace(0, 30, 100)
        fares = [fare_amount + d * 2.5 for d in distances]
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.plot(distances, fares)
        ax.scatter([trip_distance], [fare_amount + trip_distance * 2.5], color='red', s=100)
        ax.set_xlabel('Trip Distance (miles)')
        ax.set_ylabel('Fare Amount ($)')
        ax.set_title('Fare vs Distance')
        ax.grid(True)
        st.pyplot(fig)

    with tab2:
        st.subheader("Fare by Time of Day")
        hours = list(range(24))
        hourly_fares = [15 + 5 * np.sin((h - 8) * np.pi / 12) for h in hours]
        fig, ax = plt.subplots(figsize=(10, 5))
        bars = ax.bar(hours, hourly_fares)
        bars[hour].set_color('red')
        ax.set_xlabel('Hour of Day')
        ax.set_ylabel('Average Fare ($)')
        ax.set_title('Average Fare by Hour of Day')
        ax.set_xticks(hours)
        st.pyplot(fig)

    with tab3:
        st.subheader("Payments by Type")
        payment_labels = list(payment_options.keys())
        payment_counts = [40, 30, 5, 3, 2]
        fig, ax = plt.subplots(figsize=(8, 8))
        ax.pie(payment_counts, labels=payment_labels, autopct='%1.1f%%', startangle=90)
        ax.set_title('Payment Type Distribution')
        ax.axis('equal')
        st.pyplot(fig)

    # Tips and information
    st.header("Tips for Taxi Users")
    tips = [
        "The base fare for NYC green taxis is $2.50.",
        "MTA tax of $0.50 is added to all rides.",
        "Trips between 4 PM and 8 PM on weekdays (excluding holidays) include a $1.00 rush hour surcharge.",
        "There is a NYS congestion surcharge of $2.50 for trips that start, end or pass through Manhattan below 96th Street.",
        "Always ask for a receipt as proof of your trip.",
        "You can pay with credit card, cash, or via a mobile app."
    ]
    for tip in tips:
        st.markdown(f"• {tip}")

    # Disclaimer
    st.info("Note: This is a simplified model for demonstration purposes. A real model would use a trained machine learning algorithm based on historical data.")

    # Map visualization
    st.header("NYC Taxi Zone Map")
    st.write("This visualization shows the taxi zones in New York City.")
    # Placeholder for map code

if __name__ == "__main__":
    main()

